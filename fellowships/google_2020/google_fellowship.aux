\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{dzindolet2003role,herlocker2000explaining,ribeiro2016should}
\citation{lipton2018mythos}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces  Several Google services provide some form of explanatory information. Top: Gmail Magic tool suggests why an email was marked important. Bottom left: a search result highlights article tokens that are similar to the query tokens. Bottom right: the quick access tool offers brief reasons for the recommended documents in Google Drive. \relax }}{1}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:google}{{1}{1}{Several Google services provide some form of explanatory information. Top: Gmail Magic tool suggests why an email was marked important. Bottom left: a search result highlights article tokens that are similar to the query tokens. Bottom right: the quick access tool offers brief reasons for the recommended documents in Google Drive. \relax }{figure.caption.1}{}}
\newlabel{fig:google@cref}{{[figure][1][]1}{1}}
\citation{caruana2015intelligible,weld2019challenge}
\citation{lipton2018mythos}
\citation{ribeiro2016should,simonyan2013deep}
\citation{lei2016rationalizing,lehman2019inferring}
\citation{kaushik2019learning}
\citation{kaushik2019learning}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  Why these ads? Partial explanations for the displayed advertisements. \relax }}{2}{figure.caption.2}}
\newlabel{fig:google_ads}{{2}{2}{Why these ads? Partial explanations for the displayed advertisements. \relax }{figure.caption.2}{}}
\newlabel{fig:google_ads@cref}{{[figure][2][]2}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Ongoing and Past Research}{2}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Evidence Extraction}{2}{subsection.2.1}}
\newlabel{evidence}{{2.1}{2}{Evidence Extraction}{subsection.2.1}{}}
\newlabel{evidence@cref}{{[subsection][1][2]2.1}{2}}
\citation{lafferty2001conditional}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Non cherry-picked evidence extractions from our approach. We condition our extraction model on both the \hlp {\textbf  {positive}} and the \hln {\textbf  {negative}} label. Our approach is able to tailor the extractions as per the conditioned label.\relax }}{3}{table.caption.3}}
\newlabel{tbl:qual_example}{{1}{3}{Non cherry-picked evidence extractions from our approach. We condition our extraction model on both the \hlp {\textbf {positive}} and the \hln {\textbf {negative}} label. Our approach is able to tailor the extractions as per the conditioned label.\relax }{table.caption.3}{}}
\newlabel{tbl:qual_example@cref}{{[table][1][]1}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Explanations as Communication}{3}{subsection.2.2}}
\newlabel{communication}{{2.2}{3}{Explanations as Communication}{subsection.2.2}{}}
\newlabel{communication@cref}{{[subsection][2][2]2.2}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Explanation as communication framework.\relax }}{3}{figure.caption.4}}
\newlabel{fig:communication}{{3}{3}{Explanation as communication framework.\relax }{figure.caption.4}{}}
\newlabel{fig:communication@cref}{{[figure][3][]3}{3}}
\citation{pruthi19learning}
\citation{garrard2001prototypicality,mcrae2005semantic}
\citation{pruthi2018spine}
\bibstyle{plainnat}
\bibdata{refs}
\bibcite{caruana2015intelligible}{{1}{2015}{{Caruana et~al.}}{{Caruana, Lou, Gehrke, Koch, Sturm, and Elhadad}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Manipulating Explanations}{4}{subsection.2.3}}
\newlabel{attention}{{2.3}{4}{Manipulating Explanations}{subsection.2.3}{}}
\newlabel{attention@cref}{{[subsection][3][2]2.3}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Interpretable Representations}{4}{subsection.2.4}}
\newlabel{spine}{{2.4}{4}{Interpretable Representations}{subsection.2.4}{}}
\newlabel{spine@cref}{{[subsection][4][2]2.4}{4}}
\bibcite{dzindolet2003role}{{2}{2003}{{Dzindolet et~al.}}{{Dzindolet, Peterson, Pomranky, Pierce, and Beck}}}
\bibcite{garrard2001prototypicality}{{3}{2001}{{Garrard et~al.}}{{Garrard, Lambon~Ralph, Hodges, and Patterson}}}
\bibcite{herlocker2000explaining}{{4}{2000}{{Herlocker et~al.}}{{Herlocker, Konstan, and Riedl}}}
\bibcite{kaushik2019learning}{{5}{2019}{{Kaushik et~al.}}{{Kaushik, Hovy, and Lipton}}}
\bibcite{lafferty2001conditional}{{6}{2001}{{Lafferty et~al.}}{{Lafferty, McCallum, and Pereira}}}
\bibcite{lehman2019inferring}{{7}{2019}{{Lehman et~al.}}{{Lehman, DeYoung, Barzilay, and Wallace}}}
\bibcite{lei2016rationalizing}{{8}{2016}{{Lei et~al.}}{{Lei, Barzilay, and Jaakkola}}}
\bibcite{lipton2018mythos}{{9}{2018}{{Lipton}}{{}}}
\bibcite{mcrae2005semantic}{{10}{2005}{{McRae et~al.}}{{McRae, Cree, Seidenberg, and McNorgan}}}
\bibcite{pruthi2018spine}{{11}{2018}{{Pruthi et~al.}}{{Pruthi, Subramanian, Jhamtani, Berg-Kirkpatrick, and Hovy}}}
\bibcite{pruthi19learning}{{12}{2020}{{Pruthi et~al.}}{{Pruthi, Gupta, Dhingra, Neubig, and Lipton}}}
\bibcite{ribeiro2016should}{{13}{2016}{{Ribeiro et~al.}}{{Ribeiro, Singh, and Guestrin}}}
\bibcite{simonyan2013deep}{{14}{2013}{{Simonyan et~al.}}{{Simonyan, Vedaldi, and Zisserman}}}
\bibcite{weld2019challenge}{{15}{2019}{{Weld and Bansal}}{{}}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Depiction of our $k$-sparse autoencoder for an input word `internet'. Our variant of the $k$-sparse autoencoder attempts to reconstruct the input at its output layer, with only a few active hidden units (depicted in green). These active units correspond to an interpretable set of dimensions associated with the word `internet'. The rest of the dimensions (depicted in orange) are inactive for this word.\relax }}{5}{figure.caption.5}}
\newlabel{fig:autoencoder}{{4}{5}{Depiction of our $k$-sparse autoencoder for an input word `internet'. Our variant of the $k$-sparse autoencoder attempts to reconstruct the input at its output layer, with only a few active hidden units (depicted in green). These active units correspond to an interpretable set of dimensions associated with the word `internet'. The rest of the dimensions (depicted in orange) are inactive for this word.\relax }{figure.caption.5}{}}
\newlabel{fig:autoencoder@cref}{{[figure][4][]4}{5}}
